{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b97bc2d-e8c0-437e-8fb1-d89e4818d2a2",
   "metadata": {},
   "source": [
    "### Use `@traceable` / `traceable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffae2a8-4c7b-4c67-b0c6-dd1ae9a6b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "openai = Client()\n",
    "\n",
    "@traceable\n",
    "def format_prompt(subject):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"What's a good name for a store that sells {subject}?\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def invoke_llm(messages):\n",
    "    return openai.chat.completions.create(\n",
    "        messages=messages, model=\"gpt-4o-mini\", temperature=0\n",
    "    )\n",
    "\n",
    "@traceable\n",
    "def parse_output(response):\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@traceable\n",
    "def run_pipeline(subject: str):\n",
    "    messages = format_prompt(subject)\n",
    "    response = invoke_llm(messages)\n",
    "    return parse_output(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6070c2dc-2ba6-43ef-a990-69815130e8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some fun and catchy name ideas for a store that sells colorful socks:\\n\\n1. Sock It to Me\\n2. Colorful Toes\\n3. Happy Feet Boutique\\n4. The Sock Spectrum\\n5. Rainbow Socks Co.\\n6. Funky Footwear\\n7. Sock Parade\\n8. Dazzle Socks\\n9. Vibrant Soles\\n10. The Sock Garden\\n\\nFeel free to mix and match or modify these suggestions to find the perfect name for your store!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500a2de-63d1-4cb3-8184-1c7e3847b0a4",
   "metadata": {},
   "source": [
    "### Use the `trace` context manager (Python only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4c8f11-1be8-4acc-9f51-6e0e070bbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import langsmith as ls\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@ls.traceable(run_type='tool', name='Retrieve Context')\n",
    "def my_tool(question: str) -> str:\n",
    "    return \"During this morning's meeting, we solved all world conflict.\"\n",
    "\n",
    "def chat_pipeline(question: str):\n",
    "    context = my_tool(question)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\\nContext: {context}\"}\n",
    "    ]\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", messages=messages\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "app_inputs = {\"input\": \"Can you summarize this morning's meetings?\"}\n",
    "\n",
    "with ls.trace(\"Chat Pipeline\", \"chain\", project_name=\"my_test\", inputs=app_inputs) as rt:\n",
    "    output = chat_pipeline(\"Can you summarize this morning's meetings?\")\n",
    "    rt.end(outputs={\"output\": output})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f0eeb-70f7-4ff6-920d-d2b30c07f6bf",
   "metadata": {},
   "source": [
    "### Wrap the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743ca47a-a666-4a2b-a623-ed14e054242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This morning's meeting was highly productive, as the attendees successfully addressed and resolved all world conflicts.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@traceable(run_type=\"tool\", name=\"Retrieve Context\")\n",
    "def my_tool(question: str) -> str:\n",
    "    return \"During this morning's meeting, we solved all world conflict.\"\n",
    "\n",
    "@traceable(name=\"Chat Pipeline\")\n",
    "def chat_pipeline(question: str):\n",
    "    context = my_tool(question)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\\nContext: {context}\"}\n",
    "    ]\n",
    "    chat_completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o-mini\", messages=messages\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "chat_pipeline(\"Can you summarize this morning's meetings?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81028a8-41c5-4794-9f79-95cbc4e70cba",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a52b9d-f0c4-42fb-ae08-73b879405ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Callable, Type, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def traceable_cls(cls: Type[T]) -> Type[T]:\n",
    "    \"\"\"Instrument all public methods in a class.\"\"\"\n",
    "    \n",
    "    def wrap_method(name: str, method: Any) -> Any:\n",
    "        if callable(method) and not name.startswith('__'):\n",
    "            return traceable(name=f\"{cls.__name__}.{name}\")(method)\n",
    "        return method\n",
    "\n",
    "    # Handle __dict__ case\n",
    "    for name in dir(cls):\n",
    "        if not name.startswith(\"_\"):\n",
    "            try:\n",
    "                method = getattr(cls, name)\n",
    "                setattr(cls, name, wrap_method(name, method))\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    # Handle __slots__ case\n",
    "    if hasattr(cls, \"__slots__\"):\n",
    "        for slot in cls.__slots__:  # type: ignore[attr-defined]\n",
    "            if not slot.startswith(\"__\"):\n",
    "                try:\n",
    "                    method = getattr(cls, slot)\n",
    "                    setattr(cls, slot, wrap_method(slot, method))\n",
    "                except AttributeError:\n",
    "                    # Skip slots that don't have a value yet\n",
    "                    pass\n",
    "\n",
    "    return cls\n",
    "\n",
    "@traceable_cls\n",
    "class MyClass:\n",
    "    def __init__(self, some_val: int):\n",
    "        self.some_val = some_val\n",
    "\n",
    "    def combine(self, other_val: int):\n",
    "        return self.some_val + other_val\n",
    "\n",
    "MyClass(13).combine(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb8e6e-20ad-473d-8ece-b09de344a361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
