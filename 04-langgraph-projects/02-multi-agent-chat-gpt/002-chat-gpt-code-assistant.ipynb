{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccddd24a-2ef9-4372-b7f9-49def56a80d9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99dea02-28ad-4b3c-9266-496c7b2b24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Annotated, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfecdc7-2cc6-4248-b771-8c0a85c687d2",
   "metadata": {},
   "source": [
    "### Tool - image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d5bd56-1c3b-436c-bc3a-919557e39eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Define schema for generating image using DALL-E\n",
    "class GenImageSchema(BaseModel):\n",
    "    prompt: str = Field(description=\"The prompt for image generation\")\n",
    "\n",
    "\n",
    "@tool(args_schema=GenImageSchema)\n",
    "def generate_image(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an image using DALL-E based on the given prompt.\n",
    "    \"\"\"\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1\n",
    "    )\n",
    "    return response.data[0].url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac30e1f-1063-4dab-9f59-0259b06b7d8c",
   "metadata": {},
   "source": [
    "### Tool - Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5891db-0fa0-4e8d-885e-cf8c41c28f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to excute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Use this to execute python code.\n",
    "    This is visible to the user. Please use ploly to visualize.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930047f1-7320-4684-8fe5-686014b8f972",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c05cce-de63-46c1-9f56-96d87e0c3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "Today is {datetime.now().strftime(\"%Y-%m-%d\")}\n",
    "You are a helpful AI Assistant that can use web search tool(tavily ai api), image generation tool(DallE API) and code execution tool(Python REPL).\n",
    "You should always answer in same language as user's ask.\n",
    "When user ask about the information that you can't answer, you can call the search tool.\n",
    "When user ask about generating image, you can call the generate_image tool.\n",
    "When user ask about Data analysis, data visualization or code execution image, you can call the python repl tool.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "search = TavilySearchResults(max_results=5)\n",
    "\n",
    "tools = [search, generate_image, python_repl]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "chain = prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "702ae369-ae4d-4ab7-9840-2bf07b6228d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_LZakCy4UyoRjj8wd2m7zif01', 'function': {'arguments': '{\"query\":\"대한민국 GDP 추이\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 283, 'total_tokens': 305, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-f7eb51d9-2346-4275-a0fd-5ea5acef2fff-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '대한민국 GDP 추이'}, 'id': 'call_LZakCy4UyoRjj8wd2m7zif01', 'type': 'tool_call'}] usage_metadata={'input_tokens': 283, 'output_tokens': 22, 'total_tokens': 305, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"대한민국 GDP 추이를 그래프로 그려줘\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb10a91-a995-4ac0-abe0-69813ef9863d",
   "metadata": {},
   "source": [
    "### Building Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7894f1d-03de-41a3-a97b-f5d0cb7449c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [chain.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097e6e5-87ed-45e0-9e29-096c4fdc6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", input(\"User: \"))]}, config, stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecf5e6-1d74-4b5e-bdf2-6bab550d6d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
